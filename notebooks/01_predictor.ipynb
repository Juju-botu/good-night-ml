{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from datetime import date\n",
    "import datetime\n",
    "from datetime import timedelta  \n",
    "import csv\n",
    "import holidays # for importing the public holidays\n",
    "import re\n",
    "import torch\n",
    "\n",
    "from src.utils import *\n",
    "from src.data_miner import DataMiner\n",
    "from src.models import MLP\n",
    "from src.dataset import GoodNightDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 5\n",
    "min_hour = 21 # Minimum hour for sleep detection\n",
    "max_hour = 5 # Maximum hour for sleep detection\n",
    "train_window = 3 # Sequence length of past days\n",
    "local_holidays = holidays.Italy(prov='BO') # Get the holidays in Bologna, Italy :)\n",
    "EPOCHS = 500\n",
    "batch_size = 16\n",
    "# Directories\n",
    "data_dir = \"data\"\n",
    "data_file = \"data/LastSeenDataset.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Feature extraction: we first extract the features given the time series data of Telegram accesses.\n",
    "- Supposition: last Telegram access in very similar to the time the person goes to sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open Data File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First day is holiday:  False\n"
     ]
    }
   ],
   "source": [
    "with open(data_file, newline='') as csvfile:\n",
    "    date_list = list(csv.reader(csvfile))\n",
    "\n",
    "date_list = convert_to_dates(date_list)\n",
    "\n",
    "'''Test data: search calendar for local holidays'''\n",
    "print(\"First day is holiday: \", date_list[0][0] in local_holidays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "Possible features to extract: \n",
    "1. Last seen time (arguably the most important)\n",
    "2. Wake up time\n",
    "3. Number of Telegram accesses during the previous day\n",
    "4. Day of the week\n",
    "5. Public holiday presence in the following day (using the holidays library)\n",
    "6. (time spent on Telegram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tensor =  DataMiner(date_list).to_tensor(verbose=False)\n",
    "# print(data_tensor)\n",
    "n_features = num_features # this is number of parallel inputs\n",
    "n_timesteps = train_window # this is number of timesteps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "Since we want to predict simple time series data, we can employ:\n",
    "- MPL: Multi Layer Perceptron, simple deep neural network with hidden layer\n",
    "- RNN: Recurrent Neural Network, more suitable for time series\n",
    "- LSTM: Long Short Term Memory, an advancement of RNN\n",
    "- Transformer: currently (2020) state of the art, but complex and possibly overpower\n",
    "- ... Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(n_features*n_timesteps, 1)\n",
    "criterion = torch.nn.MSELoss() # reduction='sum' created huge loss value\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GoodNightDataset(data_file, n_timesteps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the training data is not much, we can insert some noise to augment it; this will also make the model less prone to overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.noisy() # apply gaussian noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   10  | Total mean loss: 0.246021 \n",
      "Epoch:   20  | Total mean loss: 0.067236 \n",
      "Epoch:   30  | Total mean loss: 0.046674 \n",
      "Epoch:   40  | Total mean loss: 0.042729 \n",
      "Epoch:   50  | Total mean loss: 0.030918 \n",
      "Epoch:   60  | Total mean loss: 0.031948 \n",
      "Epoch:   70  | Total mean loss: 0.031738 \n",
      "Epoch:   80  | Total mean loss: 0.022974 \n",
      "Epoch:   90  | Total mean loss: 0.029274 \n",
      "Epoch:  100  | Total mean loss: 0.026619 \n",
      "Epoch:  110  | Total mean loss: 0.022413 \n",
      "Epoch:  120  | Total mean loss: 0.021658 \n",
      "Epoch:  130  | Total mean loss: 0.023719 \n",
      "Epoch:  140  | Total mean loss: 0.022066 \n",
      "Epoch:  150  | Total mean loss: 0.021249 \n",
      "Epoch:  160  | Total mean loss: 0.021422 \n",
      "Epoch:  170  | Total mean loss: 0.019611 \n",
      "Epoch:  180  | Total mean loss: 0.019892 \n",
      "Epoch:  190  | Total mean loss: 0.018941 \n",
      "Epoch:  200  | Total mean loss: 0.017903 \n",
      "Epoch:  210  | Total mean loss: 0.021144 \n",
      "Epoch:  220  | Total mean loss: 0.017884 \n",
      "Epoch:  230  | Total mean loss: 0.017367 \n",
      "Epoch:  240  | Total mean loss: 0.017786 \n",
      "Epoch:  250  | Total mean loss: 0.018787 \n",
      "Epoch:  260  | Total mean loss: 0.017071 \n",
      "Epoch:  270  | Total mean loss: 0.019287 \n",
      "Epoch:  280  | Total mean loss: 0.015486 \n",
      "Epoch:  290  | Total mean loss: 0.015964 \n",
      "Epoch:  300  | Total mean loss: 0.014342 \n",
      "Epoch:  310  | Total mean loss: 0.015106 \n",
      "Epoch:  320  | Total mean loss: 0.015421 \n",
      "Epoch:  330  | Total mean loss: 0.017059 \n",
      "Epoch:  340  | Total mean loss: 0.015583 \n",
      "Epoch:  350  | Total mean loss: 0.015673 \n",
      "Epoch:  360  | Total mean loss: 0.013630 \n",
      "Epoch:  370  | Total mean loss: 0.012685 \n",
      "Epoch:  380  | Total mean loss: 0.012509 \n",
      "Epoch:  390  | Total mean loss: 0.010455 \n",
      "Epoch:  400  | Total mean loss: 0.011318 \n",
      "Epoch:  410  | Total mean loss: 0.011830 \n",
      "Epoch:  420  | Total mean loss: 0.009584 \n",
      "Epoch:  430  | Total mean loss: 0.010400 \n",
      "Epoch:  440  | Total mean loss: 0.007713 \n",
      "Epoch:  450  | Total mean loss: 0.008385 \n",
      "Epoch:  460  | Total mean loss: 0.006614 \n",
      "Epoch:  470  | Total mean loss: 0.008297 \n",
      "Epoch:  480  | Total mean loss: 0.006355 \n",
      "Epoch:  490  | Total mean loss: 0.006989 \n"
     ]
    }
   ],
   "source": [
    "trainloader = torch.utils.data.DataLoader(dataset,\n",
    "                                         batch_size=batch_size, shuffle=True,\n",
    "                                         num_workers=0)               \n",
    "model.train()\n",
    "\n",
    "losses = []\n",
    "\n",
    "# Training loop\n",
    "for t in range(EPOCHS):\n",
    "    X, y = next(iter(trainloader))\n",
    "    optimizer.zero_grad()\n",
    "    prediction = model.forward(X.reshape(batch_size, n_features*n_timesteps))\n",
    "    loss = criterion(prediction, y)  \n",
    "    loss.backward()\n",
    "    optimizer.step()        \n",
    "    losses.append(loss.item())\n",
    "    if t%10 == 0 and t >= 10:\n",
    "        print(('Epoch: {:4}  | Total mean loss: {:.6f} ').format(t, mean(losses[t-10:t])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation on training data\n",
    "We use the trained model to predict the same data as before, this time with no noise.\n",
    "Notice that we are going to overfit if we train for too long\n",
    "Potential fixes:\n",
    "- Use validation loss\n",
    "- Use higher noise value\n",
    "- Use different noise generator\n",
    "- Find another way to augment the data\n",
    "- Collect more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 0.5508 | Real: 0.5033\n",
      "Predicted: 0.5828 | Real: 0.4888\n",
      "Predicted: 0.5032 | Real: 0.5380\n",
      "Predicted: 0.4785 | Real: 0.5200\n",
      "Predicted: 0.5570 | Real: 0.6680\n",
      "Predicted: 0.4035 | Real: 0.1981\n",
      "Predicted: 0.5543 | Real: 0.5418\n",
      "Predicted: 0.5749 | Real: 0.5891\n",
      "Predicted: 0.5290 | Real: 0.5230\n",
      "Predicted: 0.5929 | Real: 0.5878\n",
      "Predicted: 0.3872 | Real: 0.2870\n",
      "Predicted: 0.2527 | Real: 0.1545\n",
      "Predicted: 0.3441 | Real: 0.3483\n",
      "Predicted: 0.1001 | Real: 0.1007\n",
      "Predicted: 0.6871 | Real: 0.6694\n",
      "Predicted: 0.5279 | Real: 0.5091\n",
      "Predicted: 0.5201 | Real: 0.4906\n",
      "Predicted: 0.6158 | Real: 0.6093\n",
      "Predicted: 0.6287 | Real: 0.6412\n",
      "Predicted: 0.6608 | Real: 0.8530\n",
      "Predicted: 0.3939 | Real: 0.3883\n",
      "Predicted: 0.5692 | Real: 0.5664\n",
      "Predicted: 0.7738 | Real: 0.7656\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for i in range(len(dataset)):\n",
    "        X, y = dataset[i]\n",
    "        prediction = model.forward(X.reshape(1,15)).item()\n",
    "        real = y.T.item()\n",
    "        print('Predicted: {:.4f} | Real: {:.4f}'.format(prediction, real))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the predicted time to send the message in a file, so that the Daemon can handle it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5492951273918152\n",
      "Expected time to go to sleep:  2020-12-28 01:23:39\n"
     ]
    }
   ],
   "source": [
    "now = datetime.datetime.now()\n",
    "seq_length = 3\n",
    "with open(data_file, newline='') as csvfile:\n",
    "    date_list = list(csv.reader(csvfile))\n",
    "date_list = convert_to_dates(date_list)\n",
    "data_tensor =  DataMiner(date_list).to_tensor(verbose=False)\n",
    "X, y = create_sequences(data_tensor, seq_length)\n",
    "x = get_latest_sequence(data_tensor, seq_length)\n",
    "\n",
    "with torch.no_grad():\n",
    "    p = model.forward(x.reshape(1,15)).item()\n",
    "print(p)\n",
    "p_sec = int(p*(max_hour+24-min_hour)*3600)\n",
    "prediction = now.replace(hour=min_hour, minute=0, second=0) + timedelta(seconds=p_sec)\n",
    "print('Expected time to go to sleep: ', prediction.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "\n",
    "'''Write the value on a text file to be read by the Daemon'''\n",
    "with open ('prediction.txt','w') as z:\n",
    "    z.write(prediction.strftime(\"%Y-%m-%d %H:%M:%S\\n\"))\n",
    "z.close()\n",
    "\n",
    "with open ('data/prediction_list.txt','a') as z:\n",
    "    z.write(prediction.strftime(\"%Y-%m-%d %H:%M:%S\\n\"))\n",
    "z.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
