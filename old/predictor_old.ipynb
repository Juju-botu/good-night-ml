{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from datetime import date\n",
    "import datetime\n",
    "from datetime import timedelta  \n",
    "import csv\n",
    "import holidays # for importing the public holidays\n",
    "import re\n",
    "\n",
    "bologna_holidays = holidays.Italy(prov='BO') # Get the holidays in Bologna, Italy :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "data_dir = \"data\"\n",
    "dataset = \"data/LastSeenDataset.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Feature extraction: we first extract the features given the time series data of Telegram accesses.\n",
    "- Supposition: last Telegram access in very similar to the time the person goes to sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "Possible features to extract: \n",
    "1. Last seen time (arguably the most important)\n",
    "2. Wake up time\n",
    "3. Number of Telegram accesses during the previous day\n",
    "4. Day of the week\n",
    "5. Public holiday presence in the following day (using the holidays library)\n",
    "6. (time spent on Telegram)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nWe don't need these functions since we have already converte\\ndef date_time_separate(data):\\n    for i in range(len(data)):\\n        d = (re.split(' ', str(data[i][0]))[0])\\n        #d = d.split('-')\\n        t = (re.split(' ', str(data[i][0]))[1])\\n        #t = t.split(':')\\n        data[i] = [d, t]\\n    return data\\n\\ndef singe_value_split(data):\\n    for i in range(len(data)):\\n        d = (re.split(' ', str(data[i][0]))[0])\\n        d = d.split('-')\\n        t = (re.split(' ', str(data[i][0]))[1])\\n        t = t.split(':')\\n        data[i] = [d, t]\\n    return data\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## OLD FUNCTIONS\n",
    "'''\n",
    "We don't need these functions since we have already converte\n",
    "def date_time_separate(data):\n",
    "    for i in range(len(data)):\n",
    "        d = (re.split(' ', str(data[i][0]))[0])\n",
    "        #d = d.split('-')\n",
    "        t = (re.split(' ', str(data[i][0]))[1])\n",
    "        #t = t.split(':')\n",
    "        data[i] = [d, t]\n",
    "    return data\n",
    "\n",
    "def singe_value_split(data):\n",
    "    for i in range(len(data)):\n",
    "        d = (re.split(' ', str(data[i][0]))[0])\n",
    "        d = d.split('-')\n",
    "        t = (re.split(' ', str(data[i][0]))[1])\n",
    "        t = t.split(':')\n",
    "        data[i] = [d, t]\n",
    "    return data\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "2020\n"
     ]
    }
   ],
   "source": [
    "with open(dataset, newline='') as csvfile:\n",
    "    date_list = list(csv.reader(csvfile))\n",
    "\n",
    "# Transform all the elements in the dataset into date objects and sort them\n",
    "def convert_to_dates(dates):\n",
    "    for i in range(len(dates)):\n",
    "        dates[i][0] = datetime.datetime.strptime(dates[i][0], \"%Y-%m-%d %H:%M:%S\" ) \n",
    "    return sorted(dates)\n",
    "\n",
    "date_list = convert_to_dates(date_list)\n",
    "\n",
    "print(date_list[0][0] in bologna_holidays)\n",
    "\n",
    "print(date_list[0][0].year)\n",
    "#print(date_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fall asleep time:  [datetime.datetime(2020, 10, 18, 1, 48, 7), datetime.datetime(2020, 10, 19, 1, 20, 51), datetime.datetime(2020, 10, 20, 0, 34, 19), datetime.datetime(2020, 10, 21, 1, 1, 35), datetime.datetime(2020, 10, 22, 0, 54, 36), datetime.datetime(2020, 10, 23, 1, 18, 14), datetime.datetime(2020, 10, 24, 1, 18, 14), datetime.datetime(2020, 10, 25, 2, 20, 39), datetime.datetime(2020, 10, 25, 22, 35, 4), datetime.datetime(2020, 10, 27, 1, 20, 5), datetime.datetime(2020, 10, 28, 1, 42, 46), datetime.datetime(2020, 10, 29, 1, 11, 3), datetime.datetime(2020, 10, 30, 1, 42, 10), datetime.datetime(2020, 10, 30, 23, 17, 47), datetime.datetime(2020, 10, 31, 22, 14, 9), datetime.datetime(2020, 11, 1, 23, 47, 12), datetime.datetime(2020, 11, 2, 21, 48, 19), datetime.datetime(2020, 11, 4, 2, 21, 20), datetime.datetime(2020, 11, 5, 1, 4, 23), datetime.datetime(2020, 11, 6, 0, 55, 28), datetime.datetime(2020, 11, 7, 1, 52, 29)]\n",
      "Wake up time:  [datetime.datetime(2020, 10, 18, 9, 48, 7), datetime.datetime(2020, 10, 19, 8, 32, 11), datetime.datetime(2020, 10, 20, 8, 33, 18), datetime.datetime(2020, 10, 21, 8, 45, 39), datetime.datetime(2020, 10, 22, 10, 16, 17), datetime.datetime(2020, 10, 23, 9, 34, 35), datetime.datetime(2020, 10, 24, 9, 34, 35), datetime.datetime(2020, 10, 25, 1, 18, 14), datetime.datetime(2020, 10, 26, 10, 38, 33), datetime.datetime(2020, 10, 27, 8, 52, 6), datetime.datetime(2020, 10, 28, 10, 14, 18), datetime.datetime(2020, 10, 29, 9, 34, 10), datetime.datetime(2020, 10, 30, 9, 21, 51), datetime.datetime(2020, 10, 31, 9, 23, 6), datetime.datetime(2020, 11, 1, 9, 12, 39), datetime.datetime(2020, 11, 2, 9, 13, 17), datetime.datetime(2020, 11, 3, 11, 56, 43), datetime.datetime(2020, 11, 4, 7, 11, 42), datetime.datetime(2020, 11, 5, 9, 8, 26), datetime.datetime(2020, 11, 6, 9, 18, 37), datetime.datetime(2020, 11, 7, 9, 6, 54)]\n",
      "Fall asleep time (seconds from MIN):  [17287.0, 15651.0, 12859.0, 14495.0, 14076.0, 15494.0, 14977.0, 19239.0, 5704.0, 15605.0, 16966.0, 15063.0, 16930.0, 8267.0, 4449.0, 10032.0, 2899.0, 19280.0, 14663.0, 14128.0, 17549.0]\n",
      "Time slept (seconds):  [28800.0, 25880.0, 28739.0, 27844.0, 33701.0, 29781.0, 29124.166666666668, -3745.0, 43409.0, 27121.0, 30692.0, 30187.0, 27581.0, 36319.0, 39510.0, 33965.0, 50904.0, 17422.0, 29043.0, 30189.0, 26065.0]\n",
      "Day of the week (from 0 = Monday):  [6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5]\n",
      "Holiday presence:  [False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False]\n",
      "Number of accesses:  [14, 12, 6, 5, 7, 14, 9.666666666666666, 18, 3, 21, 34, 14, 26, 22, 5, 17, 3, 39, 36, 25, 26]\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean ## needed for avoiding outliers\n",
    "\n",
    "# Detect last seen time at night\n",
    "\n",
    "fall_asleep_datetime = []\n",
    "wake_up_datetime = []\n",
    "\n",
    "fall_asleep = [] # array containing seconds from MIN_XX time to go to bed\n",
    "time_slept = []\n",
    "day_of_week = []\n",
    "holiday_presence = []\n",
    "num_accesses = []\n",
    "\n",
    "# Last seen during this time will be considered as last seen time\n",
    "# BEWARE: cannot detect times out of this range\n",
    "MIN_H, MIN_M, MIN_S = 21, 0, 0\n",
    "MAX_H, MAX_M, MAX_S = 5, 0, 0\n",
    "MAX_SLEPT = 12 # In hours\n",
    "MAX_ACCESSES = 100\n",
    "NUM_FEATURES = 5 # features we choose to use\n",
    "\n",
    "## Suppose detection started before MIN_HOUR\n",
    "# Initialize\n",
    "min_asleep_time = date_list[0][0]\n",
    "min_asleep_time = min_asleep_time.replace(hour= MIN_H, minute= MIN_M, second= MIN_S)\n",
    "max_asleep_time = date_list[0][0]\n",
    "max_asleep_time = max_asleep_time.replace(day= date_list[0][0].day, hour= MAX_H, minute= MAX_M, second= MAX_S) + timedelta(days=1)\n",
    "# max_t = min_asleep_time\n",
    "# m_fall_asleep_datetime_time.hour, min_asleep_time.min, min_asleep_time.second = MIN_H, MIN_M, MIN_S\n",
    "\n",
    "saved = True\n",
    "n_accesses = 0 # initialize to 0 the counter for number of status changes\n",
    "\n",
    "# Measure relative sleeptime in seconds\n",
    "def to_time_sec(sleeptime):\n",
    "    return (sleeptime - min_asleep_time).total_seconds()# (wrong?) + 86400 # Adding seconds in a day ('cause day before))\n",
    "\n",
    "# Measure time difference in seconds\n",
    "def time_diff_sec(t_f, t_0):\n",
    "    return (t_f - t_0).total_seconds()\n",
    "\n",
    "def fill_outlier(sleeptime):\n",
    "    \"\"\"Replace data by their averages\"\"\"\n",
    "    fall_asleep_datetime.append(fall_asleep_datetime[-1] + timedelta(days=1)) # Add same sleeptime as yesterday with + 1 day\n",
    "    wake_up_datetime.append(wake_up_datetime[-1] + timedelta(days=1)) # Add same wakeup as yesterday with + 1 day\n",
    "    fall_asleep.append(mean(fall_asleep))\n",
    "    time_slept.append(mean(time_slept))\n",
    "    day_of_week.append(fall_asleep_datetime[-1].weekday())\n",
    "    holiday_presence.append(fall_asleep_datetime[-1] in bologna_holidays)\n",
    "    num_accesses.append(mean(num_accesses))\n",
    "    \n",
    "def save_data(d, n_accesses, sleeptime):\n",
    "    # We save all the data in one single time so not to create mismatches\n",
    "    '''\n",
    "    \" Fill in the blanks \"\n",
    "    Let's check if there are no new data: it means that the data was either not collected,\n",
    "    or it is an outlier: hence, let's set the new sleeptime to be the same as the last recorded one\n",
    "    '''\n",
    "    sleeptime_s = to_time_sec(sleeptime)\n",
    "#     print(sleeptime)\n",
    "    time_slept_s = time_diff_sec(d, sleeptime)\n",
    "    \n",
    "    fall_asleep_datetime.append(sleeptime)\n",
    "    wake_up_datetime.append(d)\n",
    "    fall_asleep.append(sleeptime_s)\n",
    "    time_slept.append(time_slept_s)\n",
    "    day_of_week.append(d.weekday())\n",
    "    holiday_presence.append(d in bologna_holidays)\n",
    "    num_accesses.append(n_accesses)\n",
    "\n",
    "for i in range(len(date_list)):\n",
    "    # If time is a candidate for falling asleep (=good night) then save it\n",
    "    d = date_list[i][0]\n",
    "    if d > min_asleep_time and d < max_asleep_time:\n",
    "        sleeptime = d # save this time\n",
    "        saved = False\n",
    "    else:\n",
    "        if len(fall_asleep_datetime) == 0:\n",
    "            if not saved:\n",
    "                save_data(d, n_accesses, sleeptime) # First datum is not empty, of course\n",
    "        else:\n",
    "            if (d - wake_up_datetime[-1] > timedelta(days=1, hours = MAX_SLEPT)):\n",
    "                fill_outlier(sleeptime)\n",
    "                d = (fall_asleep_datetime[-1] + timedelta(days=1))\n",
    "            if not saved:\n",
    "                save_data(d, n_accesses, sleeptime)\n",
    "        # Update indexes every first Telegram access in the morning\n",
    "        min_asleep_time = d.replace(hour= MIN_H, minute= MIN_M, second= MIN_S)\n",
    "        max_asleep_time = d.replace(day= d.day, hour= MAX_H, minute= MAX_M, second= MAX_S) + timedelta(days=1)\n",
    "        saved = True \n",
    "        n_accesses = 0\n",
    "\n",
    "    n_accesses += 1 # increase counter for every different last seen ~ number of accesses\n",
    "            \n",
    "print(\"Fall asleep time: \", fall_asleep_datetime)\n",
    "print(\"Wake up time: \", wake_up_datetime)\n",
    "\n",
    "# Data actually used for learning\n",
    "print(\"Fall asleep time (seconds from MIN): \", fall_asleep)\n",
    "print(\"Time slept (seconds): \", time_slept)\n",
    "print(\"Day of the week (from 0 = Monday): \", day_of_week)\n",
    "print(\"Holiday presence: \", holiday_presence)\n",
    "print(\"Number of accesses: \", num_accesses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.60024306  0.5434375   0.44649306  0.50329861  0.48875     0.53798611\n",
      "   0.52003472  0.66802083  0.19805556  0.54184028  0.58909722  0.52302083\n",
      "   0.58784722  0.28704861  0.15447917  0.34833333  0.10065972  0.66944444\n",
      "   0.50913194  0.49055556  0.60934028]\n",
      " [ 0.66666667  0.59907407  0.66525463  0.64453704  0.78011574  0.689375\n",
      "   0.67417052 -0.08668981  1.00483796  0.62780093  0.71046296  0.69877315\n",
      "   0.63844907  0.84071759  0.91458333  0.78622685  1.17833333  0.40328704\n",
      "   0.67229167  0.69881944  0.60335648]\n",
      " [ 1.          0.          0.16666667  0.33333333  0.5         0.66666667\n",
      "   0.83333333  1.          0.          0.16666667  0.33333333  0.5\n",
      "   0.66666667  0.83333333  1.          0.          0.16666667  0.33333333\n",
      "   0.5         0.66666667  0.83333333]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          1.          0.          0.          0.\n",
      "   0.          0.          0.        ]\n",
      " [ 0.14        0.12        0.06        0.05        0.07        0.14\n",
      "   0.09666667  0.18        0.03        0.21        0.34        0.14\n",
      "   0.26        0.22        0.05        0.17        0.03        0.39\n",
      "   0.36        0.25        0.26      ]]\n"
     ]
    }
   ],
   "source": [
    "# Data preparation for the model without PyTorch\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def to_array(data):\n",
    "    return np.array(data).reshape(-1, 1)\n",
    "\n",
    "# We preprocess the data so that they are \"normalized\" to a fixed scale (for easy time recovery)\n",
    "def build_matrix(asleep, slept, day, holiday, num_accesses):\n",
    "    num_observations = len(asleep)\n",
    "    # Transform all the arrays into tensors\n",
    "    #scaler = MinMaxScaler(feature_range=(0, (MAX_H+24-MIN_H)*3600 + (MAX_M-MIN_M)*60 + (MAX_S-MIN_S)))\n",
    "    asleep = to_array(asleep) /  ((MAX_H+24-MIN_H)*3600 + (MAX_M-MIN_M)*60 + (MAX_S-MIN_S))\n",
    "    slept = to_array(slept) / (MAX_SLEPT*3600)\n",
    "    day = to_array(day) / 6\n",
    "    holiday = to_array(holiday) # no need to normalize,  true/false\n",
    "    accesses = to_array(num_accesses)/ MAX_ACCESSES\n",
    "    return np.concatenate((asleep, slept, day, holiday, accesses)).reshape(NUM_FEATURES, num_observations)\n",
    "\n",
    "# Matrix with dimensions m x n ; m = num_features, n = num_observations\n",
    "data_matrix = build_matrix(fall_asleep, time_slept, day_of_week, holiday_presence, num_accesses)\n",
    "print(data_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: tensor([[0.6002, 0.5434, 0.4465, 0.5033],\n",
      "        [0.8000, 0.7189, 0.7983, 0.7734],\n",
      "        [1.0000, 0.0000, 0.1667, 0.3333],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5600, 0.1500, 0.5600, 0.1700]], dtype=torch.float64)\n",
      "[(tensor([[0.6002, 0.5434],\n",
      "        [0.8000, 0.7189],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.5600, 0.1500]]), tensor([0.4465], dtype=torch.float64)), (tensor([[0.5434, 0.4465],\n",
      "        [0.7189, 0.7983],\n",
      "        [0.0000, 0.1667],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.1500, 0.5600]]), tensor([0.5033], dtype=torch.float64))]\n"
     ]
    }
   ],
   "source": [
    "# Transformation to PyTorch tensor and data augmentation\n",
    "data_tensor = torch.from_numpy(data_matrix)\n",
    "print(\"Data:\", data_tensor)\n",
    "\n",
    "# Data augmentation\n",
    "# We use the \"last 3\" trend\n",
    "# Credits: https://stackabuse.com/time-series-prediction-using-lstm-with-pytorch-in-python/\n",
    "train_window = 2\n",
    "\n",
    "def create_inout_sequences(dt, tw):\n",
    "    inout_seq = []\n",
    "    L = dt.shape[1]\n",
    "    for i in range(L-tw):\n",
    "        train_seq = torch.zeros(NUM_FEATURES, tw)\n",
    "        for j in range(NUM_FEATURES):\n",
    "            train_seq[j]= dt[j][i:i+tw]\n",
    "        train_label = dt[0][i+tw:i+tw+1]\n",
    "        inout_seq.append((train_seq ,train_label))\n",
    "    print(inout_seq)\n",
    "    return inout_seq\n",
    "\n",
    "train_inout_seq = create_inout_sequences(data_tensor, train_window)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "- Time series data, so possible idea(s):\n",
    "    - LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(\n",
      "  (lstm): LSTM(5, 100)\n",
      "  (linear): Linear(in_features=100, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size=NUM_FEATURES, hidden_layer_size=100, output_size=1):\n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size)\n",
    "\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "        self.hidden_cell = (torch.zeros(1,1,self.hidden_layer_size),\n",
    "                            torch.zeros(1,1,self.hidden_layer_size))\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq) ,1, -1), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]\n",
    "    \n",
    "model = LSTM()\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 5, got 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-374-d5e38f54ea04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                         torch.zeros(1, 1, model.hidden_layer_size))\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0msingle_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-373-9669cdcc809d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_seq)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_cell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_cell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m         \u001b[0mexpected_hidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_expected_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    175\u001b[0m                     expected_input_dim, input.dim()))\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m    178\u001b[0m                 'input.size(-1) must be equal to input_size. Expected {}, got {}'.format(\n\u001b[1;32m    179\u001b[0m                     self.input_size, input.size(-1)))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 5, got 2"
     ]
    }
   ],
   "source": [
    "epochs = 150\n",
    "\n",
    "for i in range(epochs):\n",
    "    for seq, label in train_inout_seq:\n",
    "        optimizer.zero_grad()\n",
    "        model.hidden_cell = (torch.zeros(1, 1, model.hidden_layer_size),\n",
    "                        torch.zeros(1, 1, model.hidden_layer_size))\n",
    "\n",
    "        y_pred = model(seq)\n",
    "\n",
    "        single_loss = loss_function(y_pred, label)\n",
    "        single_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if i%25 == 1:\n",
    "        print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')\n",
    "\n",
    "print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
