{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from datetime import date\n",
    "import datetime\n",
    "from datetime import timedelta  \n",
    "import csv\n",
    "import holidays # for importing the public holidays\n",
    "import re\n",
    "import torch\n",
    "from src.utils import *\n",
    "from src.data_miner import DataMiner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 5\n",
    "min_hour = 21 # Minimum hour for sleep detection\n",
    "max_hour = 5 # Maximum hour for sleep detection\n",
    "train_window = 3 # Sequence length of past days\n",
    "local_holidays = holidays.Italy(prov='BO') # Get the holidays in Bologna, Italy :)\n",
    "EPOCHS = 500\n",
    "batch_size = 16\n",
    "# Directories\n",
    "data_dir = \"data\"\n",
    "dataset = \"data/LastSeenDataset.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Feature extraction: we first extract the features given the time series data of Telegram accesses.\n",
    "- Supposition: last Telegram access in very similar to the time the person goes to sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open Data File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First day is holiday:  False\n"
     ]
    }
   ],
   "source": [
    "with open(dataset, newline='') as csvfile:\n",
    "    date_list = list(csv.reader(csvfile))\n",
    "\n",
    "date_list = convert_to_dates(date_list)\n",
    "\n",
    "'''Test data: search calendar for local holidays'''\n",
    "print(\"First day is holiday: \", date_list[0][0] in local_holidays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "Possible features to extract: \n",
    "1. Last seen time (arguably the most important)\n",
    "2. Wake up time\n",
    "3. Number of Telegram accesses during the previous day\n",
    "4. Day of the week\n",
    "5. Public holiday presence in the following day (using the holidays library)\n",
    "6. (time spent on Telegram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tensor =  DataMiner(date_list).to_tensor(verbose=False)\n",
    "# print(data_tensor)\n",
    "n_features = num_features # this is number of parallel inputs\n",
    "n_timesteps = train_window # this is number of timesteps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "Since we want to predict simple time series data, we can employ:\n",
    "- MPL: Multi Layer Perceptron, simple deep neural network with hidden layer\n",
    "- RNN: Recurrent Neural Network, more suitable for time series\n",
    "- LSTM: Long Short Term Memory, an advancement of RNN\n",
    "- Transformer: currently (2020) state of the art, but complex and possibly overpower\n",
    "- ... Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import MLP\n",
    "\n",
    "model = MLP(n_features*n_timesteps, 1)\n",
    "criterion = torch.nn.MSELoss() # reduction='sum' created huge loss value\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Variables\n",
    "data_dir = \"data\"\n",
    "data_root = \"data/LastSeenDataset.csv\"\n",
    "\n",
    "class GoodNightDataset(Dataset):\n",
    "    def __init__(self, data_root, seq_length):\n",
    "        self.seq_length = seq_length\n",
    "        with open(data_root, newline='') as csvfile:\n",
    "            date_list = list(csv.reader(csvfile))\n",
    "        date_list = convert_to_dates(date_list)\n",
    "        self.data =  DataMiner(date_list).to_tensor(verbose=False)\n",
    "        self.n_features = self.data.shape[0]\n",
    "        # the sequence on which we have a prediction is the last train_window days\n",
    "        self.X, self.y = self.create_sequences()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "    \n",
    "    def _apply_noise(self, x, scale, noise):\n",
    "        \"\"\"Crop noisy datum to be in [0,1]\"\"\"\n",
    "        noisy = x + scale*noise(1)\n",
    "        if min(noisy.item(), 1) == 1:\n",
    "            noisy = torch.tensor(1)\n",
    "        if max(noisy.item(), 0 ) == 0:\n",
    "            noisy = torch.tensor(0)\n",
    "        return noisy\n",
    "\n",
    "    def create_sequences(self, data_type=torch.float32):\n",
    "        '''We create a list of training data divided in inputs X and outputs y'''\n",
    "        X = []\n",
    "        y = []\n",
    "        L = self.data.shape[1]\n",
    "        tw = self.seq_length\n",
    "        for i in range(L-tw):\n",
    "            train_seq = torch.zeros(self.n_features, tw)\n",
    "            for j in range(n_features):\n",
    "                train_seq[j]= self.data[j][i:i+tw]\n",
    "            train_label = self.data[0][i+tw:i+tw+1] \n",
    "            X.append(train_seq)\n",
    "            y.append(train_label)\n",
    "        return torch.transpose(torch.stack(X), 2, 1).type(data_type), torch.stack(y).type(data_type)\n",
    "\n",
    "    def get_latest_sequence(self, data_type=torch.float32):\n",
    "        '''Get latest sequence for making prediction'''\n",
    "        X = []\n",
    "        tw = self.seq_length\n",
    "        idx = self.data.shape[1] # index of the last element\n",
    "        seq = torch.zeros(self.n_features, tw)\n",
    "        for j in range(self.n_features):\n",
    "            seq[j]= self.data[j][idx-tw:idx]\n",
    "        X.append(seq)\n",
    "        return torch.transpose(\n",
    "            torch.stack(X), 2, 1).type(data_type)\n",
    "\n",
    "\n",
    "    def noisy(self, scale=0.05, noise=torch.randn):\n",
    "        \"\"\"Build batch with noise\"\"\"\n",
    "        for i in range(self.X.shape[0]):\n",
    "            #y[i] = self._apply_noise(y[i], scale, noise)\n",
    "            for j in range(self.X.shape[1]):\n",
    "                for k in [0, 1, 4]: # don't put noise on day of the week and festive day presence\n",
    "                    self.X[i, j, k] = self._apply_noise(self.X[i, j, k], scale, noise)         \n",
    "        return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GoodNightDataset(data_root, n_timesteps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the training data is not much, we can insert some noise to augment it; this will also make the model less prone to overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.noisy() # apply gaussian noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   10  | Total mean loss: 0.145319 \n",
      "Epoch:   20  | Total mean loss: 0.045858 \n",
      "Epoch:   30  | Total mean loss: 0.053011 \n",
      "Epoch:   40  | Total mean loss: 0.035244 \n",
      "Epoch:   50  | Total mean loss: 0.028595 \n",
      "Epoch:   60  | Total mean loss: 0.028810 \n",
      "Epoch:   70  | Total mean loss: 0.025607 \n",
      "Epoch:   80  | Total mean loss: 0.021317 \n",
      "Epoch:   90  | Total mean loss: 0.017327 \n",
      "Epoch:  100  | Total mean loss: 0.020425 \n",
      "Epoch:  110  | Total mean loss: 0.018569 \n",
      "Epoch:  120  | Total mean loss: 0.019713 \n",
      "Epoch:  130  | Total mean loss: 0.014891 \n",
      "Epoch:  140  | Total mean loss: 0.015498 \n",
      "Epoch:  150  | Total mean loss: 0.016044 \n",
      "Epoch:  160  | Total mean loss: 0.015179 \n",
      "Epoch:  170  | Total mean loss: 0.013356 \n",
      "Epoch:  180  | Total mean loss: 0.013897 \n",
      "Epoch:  190  | Total mean loss: 0.012356 \n",
      "Epoch:  200  | Total mean loss: 0.010361 \n",
      "Epoch:  210  | Total mean loss: 0.010669 \n",
      "Epoch:  220  | Total mean loss: 0.009967 \n",
      "Epoch:  230  | Total mean loss: 0.007742 \n",
      "Epoch:  240  | Total mean loss: 0.007363 \n",
      "Epoch:  250  | Total mean loss: 0.006604 \n",
      "Epoch:  260  | Total mean loss: 0.006027 \n",
      "Epoch:  270  | Total mean loss: 0.004170 \n",
      "Epoch:  280  | Total mean loss: 0.004195 \n",
      "Epoch:  290  | Total mean loss: 0.003331 \n",
      "Epoch:  300  | Total mean loss: 0.002900 \n",
      "Epoch:  310  | Total mean loss: 0.002572 \n",
      "Epoch:  320  | Total mean loss: 0.001862 \n",
      "Epoch:  330  | Total mean loss: 0.001504 \n",
      "Epoch:  340  | Total mean loss: 0.001255 \n",
      "Epoch:  350  | Total mean loss: 0.001022 \n",
      "Epoch:  360  | Total mean loss: 0.000751 \n",
      "Epoch:  370  | Total mean loss: 0.000615 \n",
      "Epoch:  380  | Total mean loss: 0.000437 \n",
      "Epoch:  390  | Total mean loss: 0.000367 \n",
      "Epoch:  400  | Total mean loss: 0.000315 \n",
      "Epoch:  410  | Total mean loss: 0.000244 \n",
      "Epoch:  420  | Total mean loss: 0.000164 \n",
      "Epoch:  430  | Total mean loss: 0.000139 \n",
      "Epoch:  440  | Total mean loss: 0.000115 \n",
      "Epoch:  450  | Total mean loss: 0.000096 \n",
      "Epoch:  460  | Total mean loss: 0.000083 \n",
      "Epoch:  470  | Total mean loss: 0.000065 \n",
      "Epoch:  480  | Total mean loss: 0.000046 \n",
      "Epoch:  490  | Total mean loss: 0.000041 \n"
     ]
    }
   ],
   "source": [
    "trainloader = torch.utils.data.DataLoader(dataset,\n",
    "                                         batch_size=batch_size, shuffle=True,\n",
    "                                         num_workers=0)               \n",
    "model.train()\n",
    "\n",
    "losses = []\n",
    "\n",
    "# Training loop\n",
    "for t in range(EPOCHS):\n",
    "    X, y = next(iter(trainloader))\n",
    "    optimizer.zero_grad()\n",
    "    prediction = model.forward(X.reshape(batch_size, n_features*n_timesteps))\n",
    "    loss = criterion(prediction, y)  \n",
    "    loss.backward()\n",
    "    optimizer.step()        \n",
    "    losses.append(loss.item())\n",
    "    if t%10 == 0 and t >= 10:\n",
    "        print(('Epoch: {:4}  | Total mean loss: {:.6f} ').format(t, mean(losses[t-10:t])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation on training data\n",
    "We use the trained model to predict the same data as before, this time with no noise.\n",
    "Notice that we are going to overfit if we train for too long\n",
    "Potential fixes:\n",
    "- Use validation loss\n",
    "- Use higher noise value\n",
    "- Use different noise generator\n",
    "- Find another way to augment the data\n",
    "- Collect more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 0.5093 | Real: 0.5033\n",
      "Predicted: 0.4884 | Real: 0.4888\n",
      "Predicted: 0.5462 | Real: 0.5380\n",
      "Predicted: 0.5114 | Real: 0.5200\n",
      "Predicted: 0.6595 | Real: 0.6680\n",
      "Predicted: 0.2033 | Real: 0.1981\n",
      "Predicted: 0.5413 | Real: 0.5418\n",
      "Predicted: 0.5869 | Real: 0.5891\n",
      "Predicted: 0.5179 | Real: 0.5230\n",
      "Predicted: 0.5877 | Real: 0.5878\n",
      "Predicted: 0.2969 | Real: 0.2870\n",
      "Predicted: 0.1509 | Real: 0.1545\n",
      "Predicted: 0.3465 | Real: 0.3483\n",
      "Predicted: 0.1009 | Real: 0.1007\n",
      "Predicted: 0.6687 | Real: 0.6694\n",
      "Predicted: 0.5124 | Real: 0.5091\n",
      "Predicted: 0.4955 | Real: 0.4906\n",
      "Predicted: 0.6114 | Real: 0.6093\n",
      "Predicted: 0.6302 | Real: 0.6412\n",
      "Predicted: 0.8566 | Real: 0.8530\n",
      "Predicted: 0.3897 | Real: 0.3883\n",
      "Predicted: 0.5587 | Real: 0.5664\n",
      "Predicted: 0.7652 | Real: 0.7656\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for i in range(len(dataset)):\n",
    "        X, y = dataset[i]\n",
    "        prediction = model.forward(X.reshape(1,15)).item()\n",
    "        real = y.T.item()\n",
    "        print('Predicted: {:.4f} | Real: {:.4f}'.format(prediction, real))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the predicted time to send the message in a file, so that the Daemon can handle it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6732186675071716\n",
      "Expected time to go to sleep:  2020-12-28 02:23:08\n"
     ]
    }
   ],
   "source": [
    "now = datetime.datetime.now()\n",
    "seq_length = 3\n",
    "with open(data_root, newline='') as csvfile:\n",
    "    date_list = list(csv.reader(csvfile))\n",
    "date_list = convert_to_dates(date_list)\n",
    "data_tensor =  DataMiner(date_list).to_tensor(verbose=False)\n",
    "X, y = create_sequences(data_tensor, seq_length)\n",
    "x = get_latest_sequence(data_tensor, seq_length)\n",
    "\n",
    "with torch.no_grad():\n",
    "    p = model.forward(x.reshape(1,15)).item()\n",
    "print(p)\n",
    "p_sec = int(p*(max_hour+24-min_hour)*3600)\n",
    "prediction = now.replace(hour=min_hour, minute=0, second=0) + timedelta(seconds=p_sec)\n",
    "print('Expected time to go to sleep: ', prediction.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "\n",
    "'''Write the value on a text file to be read by the Daemon'''\n",
    "with open ('prediction.txt','w') as z:\n",
    "    z.write(prediction.strftime(\"%Y-%m-%d %H:%M:%S\\n\"))\n",
    "z.close()\n",
    "\n",
    "with open ('data/prediction_list.txt','a') as z:\n",
    "    z.write(prediction.strftime(\"%Y-%m-%d %H:%M:%S\\n\"))\n",
    "z.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
