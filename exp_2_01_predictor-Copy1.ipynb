{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from datetime import date\n",
    "import datetime\n",
    "from datetime import timedelta  \n",
    "import csv\n",
    "import holidays # for importing the public holidays\n",
    "import re\n",
    "import torch\n",
    "from src.utils import *\n",
    "from src.data_miner import DataMiner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 5\n",
    "min_hour = 21 # Minimum hour for sleep detection\n",
    "max_hour = 5\n",
    "train_window = 3 # Sequence length\n",
    "local_holidays = holidays.Italy(prov='BO') # Get the holidays in Bologna, Italy :)\n",
    "train_episodes = 1000\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "data_dir = \"data\"\n",
    "dataset = \"data/LastSeenDataset.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Feature extraction: we first extract the features given the time series data of Telegram accesses.\n",
    "- Supposition: last Telegram access in very similar to the time the person goes to sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "Possible features to extract: \n",
    "1. Last seen time (arguably the most important)\n",
    "2. Wake up time\n",
    "3. Number of Telegram accesses during the previous day\n",
    "4. Day of the week\n",
    "5. Public holiday presence in the following day (using the holidays library)\n",
    "6. (time spent on Telegram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First day is holiday:  False\n"
     ]
    }
   ],
   "source": [
    "with open(dataset, newline='') as csvfile:\n",
    "    date_list = list(csv.reader(csvfile))\n",
    "\n",
    "date_list = convert_to_dates(date_list)\n",
    "\n",
    "'''Test data: search calendar for local holidays'''\n",
    "print(\"First day is holiday: \", date_list[0][0] in local_holidays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6002, 0.5434, 0.4465, 0.5033, 0.4888, 0.5380, 0.5200, 0.6680, 0.1981,\n",
      "         0.5418, 0.5891, 0.5230, 0.5878, 0.2870, 0.1545, 0.3483, 0.1007, 0.6694,\n",
      "         0.5091, 0.4906, 0.6093, 0.6412, 0.8530, 0.3883, 0.5664, 0.7656],\n",
      "        [0.6667, 0.5991, 0.6653, 0.6445, 0.7801, 0.6894, 0.6742, 0.6647, 1.0048,\n",
      "         0.6278, 0.7105, 0.6988, 0.6384, 0.8407, 0.9146, 0.7862, 1.1783, 0.4033,\n",
      "         0.6723, 0.6988, 0.6034, 0.5998, 0.5354, 0.7193, 0.7006, 0.5691],\n",
      "        [1.0000, 0.0000, 0.1667, 0.3333, 0.5000, 0.6667, 0.8333, 1.0000, 0.0000,\n",
      "         0.1667, 0.3333, 0.5000, 0.6667, 0.8333, 1.0000, 0.0000, 0.1667, 0.3333,\n",
      "         0.5000, 0.6667, 0.8333, 1.0000, 0.0000, 0.1667, 0.3333, 0.5000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1400, 0.1200, 0.0600, 0.0500, 0.0700, 0.1400, 0.0967, 0.1400, 0.0300,\n",
      "         0.2100, 0.3400, 0.1400, 0.2600, 0.2200, 0.0500, 0.1700, 0.0300, 0.3900,\n",
      "         0.3600, 0.2500, 0.2600, 0.3300, 0.1400, 0.0900, 0.1300, 0.2000]],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "data_tensor =  DataMiner(date_list).to_tensor(verbose=False)\n",
    "print(data_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the training data is not much, we can insert some noise to augment it; this will also make the model less prone to overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "\n",
    "\n",
    "# We use the \"last 3\" trend\n",
    "# Credits: https://stackabuse.com/time-series-prediction-using-lstm-with-pytorch-in-python/\n",
    "'''The sequence on which we have a prediction is the last train_window days'''\n",
    "X, y = create_sequences(data_tensor, train_window)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "- Time series data, so possible idea(s):\n",
    "    - LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4465, 0.6653, 0.1667, 0.0000, 0.0600],\n",
      "        [0.5033, 0.6445, 0.3333, 0.0000, 0.0500],\n",
      "        [0.4888, 0.7801, 0.5000, 0.0000, 0.0700]])\n",
      "tensor([0.4888])\n"
     ]
    }
   ],
   "source": [
    "n_features = num_features # this is number of parallel inputs\n",
    "n_timesteps = train_window # this is number of timesteps\n",
    "\n",
    "# convert dataset into input/output\n",
    "\n",
    "# create NN\n",
    "model = MLP(n_features*n_timesteps*batch_size, 1)\n",
    "criterion = torch.nn.MSELoss() # reduction='sum' created huge loss value\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "print(X[2])\n",
    "print(y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:    0   |   Loss: 0.003615 \n",
      "Step:   10   |   Loss: 0.001513 \n",
      "Step:   20   |   Loss: 0.001027 \n",
      "Step:   30   |   Loss: 0.004120 \n",
      "Step:   40   |   Loss: 0.004048 \n",
      "Step:   50   |   Loss: 0.003955 \n",
      "Step:   60   |   Loss: 0.003816 \n",
      "Step:   70   |   Loss: 0.003735 \n",
      "Step:   80   |   Loss: 0.003798 \n",
      "Step:   90   |   Loss: 0.002145 \n",
      "Step:  100   |   Loss: 0.000460 \n",
      "Step:  110   |   Loss: 0.004028 \n",
      "Step:  120   |   Loss: 0.004056 \n",
      "Step:  130   |   Loss: 0.003992 \n",
      "Step:  140   |   Loss: 0.003845 \n",
      "Step:  150   |   Loss: 0.003736 \n",
      "Step:  160   |   Loss: 0.003790 \n",
      "Step:  170   |   Loss: 0.003524 \n",
      "Step:  180   |   Loss: 0.000465 \n",
      "Step:  190   |   Loss: 0.004421 \n",
      "Step:  200   |   Loss: 0.004223 \n",
      "Step:  210   |   Loss: 0.003982 \n",
      "Step:  220   |   Loss: 0.003879 \n",
      "Step:  230   |   Loss: 0.003768 \n",
      "Step:  240   |   Loss: 0.003919 \n",
      "Step:  250   |   Loss: 0.002185 \n",
      "Step:  260   |   Loss: 0.000370 \n",
      "Step:  270   |   Loss: 0.004315 \n",
      "Step:  280   |   Loss: 0.004325 \n",
      "Step:  290   |   Loss: 0.003933 \n",
      "Step:  300   |   Loss: 0.003873 \n",
      "Step:  310   |   Loss: 0.003838 \n",
      "Step:  320   |   Loss: 0.003770 \n",
      "Step:  330   |   Loss: 0.000480 \n",
      "Step:  340   |   Loss: 0.003627 \n",
      "Step:  350   |   Loss: 0.003686 \n",
      "Step:  360   |   Loss: 0.004276 \n",
      "Step:  370   |   Loss: 0.004176 \n",
      "Step:  380   |   Loss: 0.002313 \n",
      "Step:  390   |   Loss: 0.000811 \n",
      "Step:  400   |   Loss: 0.004351 \n",
      "Step:  410   |   Loss: 0.003816 \n",
      "Step:  420   |   Loss: 0.004108 \n",
      "Step:  430   |   Loss: 0.003904 \n",
      "Step:  440   |   Loss: 0.001556 \n",
      "Step:  450   |   Loss: 0.003143 \n",
      "Step:  460   |   Loss: 0.003477 \n",
      "Step:  470   |   Loss: 0.004159 \n",
      "Step:  480   |   Loss: 0.004124 \n",
      "Step:  490   |   Loss: 0.003764 \n",
      "Step:  500   |   Loss: 0.001530 \n",
      "Step:  510   |   Loss: 0.002591 \n",
      "Step:  520   |   Loss: 0.002897 \n",
      "Step:  530   |   Loss: 0.004181 \n",
      "Step:  540   |   Loss: 0.003928 \n",
      "Step:  550   |   Loss: 0.003854 \n",
      "Step:  560   |   Loss: 0.003988 \n",
      "Step:  570   |   Loss: 0.003784 \n",
      "Step:  580   |   Loss: 0.000860 \n",
      "Step:  590   |   Loss: 0.005349 \n",
      "Step:  600   |   Loss: 0.003614 \n",
      "Step:  610   |   Loss: 0.003981 \n",
      "Step:  620   |   Loss: 0.003897 \n",
      "Step:  630   |   Loss: 0.003816 \n",
      "Step:  640   |   Loss: 0.004033 \n",
      "Step:  650   |   Loss: 0.002509 \n",
      "Step:  660   |   Loss: 0.001330 \n",
      "Step:  670   |   Loss: 0.003732 \n",
      "Step:  680   |   Loss: 0.004272 \n",
      "Step:  690   |   Loss: 0.003913 \n",
      "Step:  700   |   Loss: 0.003806 \n",
      "Step:  710   |   Loss: 0.003686 \n",
      "Step:  720   |   Loss: 0.003519 \n",
      "Step:  730   |   Loss: 0.003787 \n",
      "Step:  740   |   Loss: 0.001059 \n",
      "Step:  750   |   Loss: 0.001058 \n",
      "Step:  760   |   Loss: 0.005544 \n",
      "Step:  770   |   Loss: 0.004204 \n",
      "Step:  780   |   Loss: 0.004044 \n",
      "Step:  790   |   Loss: 0.003917 \n",
      "Step:  800   |   Loss: 0.004071 \n",
      "Step:  810   |   Loss: 0.003458 \n",
      "Step:  820   |   Loss: 0.001306 \n",
      "Step:  830   |   Loss: 0.004327 \n",
      "Step:  840   |   Loss: 0.004023 \n",
      "Step:  850   |   Loss: 0.003947 \n",
      "Step:  860   |   Loss: 0.003826 \n",
      "Step:  870   |   Loss: 0.003697 \n",
      "Step:  880   |   Loss: 0.003689 \n",
      "Step:  890   |   Loss: 0.003985 \n",
      "Step:  900   |   Loss: 0.001397 \n",
      "Step:  910   |   Loss: 0.004634 \n",
      "Step:  920   |   Loss: 0.003525 \n",
      "Step:  930   |   Loss: 0.004068 \n",
      "Step:  940   |   Loss: 0.003822 \n",
      "Step:  950   |   Loss: 0.003772 \n",
      "Step:  960   |   Loss: 0.003733 \n",
      "Step:  970   |   Loss: 0.004135 \n",
      "Step:  980   |   Loss: 0.001210 \n",
      "Step:  990   |   Loss: 0.004709 \n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "# Training loop\n",
    "for t in range(train_episodes):\n",
    "    for b in range(0,len(X)-1,batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        x_batch = X[b:b+batch_size,:,:]\n",
    "        y_batch = y[b:b+batch_size]\n",
    "#         x_batch = torch.tensor(inpt,dtype=torch.float32)    \n",
    "#         y_batch = torch.tensor(target,dtype=torch.float32)\n",
    "        output = model.forward(x_batch) \n",
    "        loss = criterion(output, y_batch)  \n",
    "#         print('PREDICTED:\\n', output); print('REAL:\\n', y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()        \n",
    "        #loss_list.append(loss.item())\n",
    "    if t%10 == 0:\n",
    "        print(('Step: {:4}   |   Loss: {:.6f} ').format(t, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 5])\n",
      "tensor([0.5172])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-d1737dbeb858>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x_batch = torch.tensor(inpt,dtype=torch.float32)\n",
      "<ipython-input-15-d1737dbeb858>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(target,dtype=torch.float32)\n",
      "<ipython-input-15-d1737dbeb858>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  output = model.forward(torch.tensor(X[-1-batch_size:-1,:,:],dtype=torch.float32))[0]\n",
      "<ipython-input-15-d1737dbeb858>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  print(model.forward(torch.tensor(X[-1-batch_size:-1,:,:],dtype=torch.float32))[0])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "b = 1\n",
    "inpt = X[-b-batch_size:-b,:,:]\n",
    "target = y[b:b+batch_size]\n",
    "x_batch = torch.tensor(inpt,dtype=torch.float32)    \n",
    "y_batch = torch.tensor(target,dtype=torch.float32)\n",
    "\n",
    "\n",
    "print(x_batch.size())\n",
    "output = model.forward(torch.tensor(X[-1-batch_size:-1,:,:],dtype=torch.float32))[0]\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(model.forward(torch.tensor(X[-1-batch_size:-1,:,:],dtype=torch.float32))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 0.4995 | Real: 0.5033\n",
      "Predicted: 0.5007 | Real: 0.4888\n",
      "Predicted: 0.5372 | Real: 0.5380\n",
      "Predicted: 0.5391 | Real: 0.5200\n",
      "Predicted: 0.6485 | Real: 0.6680\n",
      "Predicted: 0.2082 | Real: 0.1981\n",
      "Predicted: 0.5437 | Real: 0.5418\n",
      "Predicted: 0.5943 | Real: 0.5891\n",
      "Predicted: 0.5167 | Real: 0.5230\n",
      "Predicted: 0.5945 | Real: 0.5878\n",
      "Predicted: 0.1897 | Real: 0.2870\n",
      "Predicted: 0.1814 | Real: 0.1545\n",
      "Predicted: 0.3424 | Real: 0.3483\n",
      "Predicted: 0.1814 | Real: 0.1007\n",
      "Predicted: 0.6676 | Real: 0.6694\n",
      "Predicted: 0.5063 | Real: 0.5091\n",
      "Predicted: 0.5023 | Real: 0.4906\n",
      "Predicted: 0.5399 | Real: 0.6093\n",
      "Predicted: 0.5668 | Real: 0.6412\n",
      "Predicted: 0.7680 | Real: 0.8530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-e8d8f1b44bc2>:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  print('Predicted: {:.4f} | Real: {:.4f}'.format(model.forward(torch.tensor(X[i:batch_size+i,:,:])).item(), y[i+batch_size-1].item()))\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for i in range(len(X)-3):\n",
    "#         print(torch.tensor(X[i:i+1, :, : ],dtype=torch.float32).shape)\n",
    "        print('Predicted: {:.4f} | Real: {:.4f}'.format(model.forward(torch.tensor(X[i:batch_size+i,:,:])).item(), y[i+batch_size-1].item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the predicted time to send the message in a file, so that the Daemon can handle it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mv_net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-d0e53ff9876e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# with torch.no_grad():\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmv_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mp_sec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_hour\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmin_hour\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhour\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_hour\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminute\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecond\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseconds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mv_net' is not defined"
     ]
    }
   ],
   "source": [
    "now = datetime.datetime.now()\n",
    "# with torch.no_grad():\n",
    "p = mv_net.forward(torch.tensor(X[-batch_size-1:-1:,:],dtype=torch.float32))[0].detach().numpy()\n",
    "p_sec = int(p[0]*(max_hour+24-min_hour)*3600)\n",
    "prediction = now.replace(hour=min_hour, minute=0, second=0) + timedelta(seconds=p_sec)\n",
    "print('Expected time to go to sleep: ', prediction.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "\n",
    "'''Write the value on a text file to be read by the Daemon'''\n",
    "with open ('prediction.txt','w') as z:\n",
    "    z.write(prediction.strftime(\"%Y-%m-%d %H:%M:%S\\n\"))\n",
    "z.close()\n",
    "\n",
    "with open ('data/prediction_list.txt','a') as z:\n",
    "    z.write(prediction.strftime(\"%Y-%m-%d %H:%M:%S\\n\"))\n",
    "z.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
